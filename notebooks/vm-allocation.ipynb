{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runtime-Optimized VM Allocation for Benchmarks\n",
    "\n",
    "This notebook implements a bin packing algorithm to allocate benchmarks to VMs based on actual HiGHS v1.10 runtime data, aiming to minimize total runtime variance across VMs.\n",
    "\n",
    "## Important: HiGHS Variant Multiplier\n",
    "\n",
    "**We run 5 HiGHS solver variants for each benchmark:**\n",
    "1. `highs` (v1.10.0 standard)\n",
    "2. `highs-hipo-ipm` (v1.11.0 with IPM solver)\n",
    "3. `highs-hipo` (v1.11.0 with HiPO solver + 128 block size)\n",
    "4. `highs-hipo-32` (v1.11.0 with HiPO + 32 block size)\n",
    "5. `highs-hipo-64` (v1.11.0 with HiPO + 64 block size)\n",
    "\n",
    "Therefore, **actual VM runtime = base HiGHS runtime × 5**\n",
    "\n",
    "This multiplier is applied to all runtime calculations and VM allocations to accurately reflect the actual wall-clock time each VM will take to complete all benchmark variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Max runtime per VM: 96.0 hours (4.0 days)\n",
      "  HiGHS variants to run: 5\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "# CONFIGURATION\n",
    "MAX_RUNTIME_PER_VM_SECONDS = (\n",
    "    4 * 24 * 3600\n",
    ")  # 4 days = 345,600 seconds (max wall-clock time per VM)\n",
    "# MAX_RUNTIME_PER_VM_SECONDS = None  # Set to None for no limit\n",
    "\n",
    "hipo_variants = [\"highs-hipo-ipm\", \"highs-hipo-128\", \"highs-hipo-32\", \"highs-hipo-64\"]\n",
    "NUM_HIGHS_VARIANTS = len(hipo_variants) + 1  # +1 for standard 'highs'\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(\n",
    "    f\"  Max runtime per VM: {MAX_RUNTIME_PER_VM_SECONDS / 3600:.1f} hours ({MAX_RUNTIME_PER_VM_SECONDS / (24 * 3600):.1f} days)\"\n",
    "    if MAX_RUNTIME_PER_VM_SECONDS\n",
    "    else \"  No runtime cap\"\n",
    ")\n",
    "print(f\"  HiGHS variants to run: {NUM_HIGHS_VARIANTS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Process Runtime Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 120 successful HiGHS v1.10/hipo benchmark runs\n",
      "Solvers included: ['highs']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Benchmark</th>\n",
       "      <th>Size</th>\n",
       "      <th>Solver</th>\n",
       "      <th>Solver Version</th>\n",
       "      <th>Solver Release Year</th>\n",
       "      <th>Status</th>\n",
       "      <th>Termination Condition</th>\n",
       "      <th>Runtime (s)</th>\n",
       "      <th>Memory Usage (MB)</th>\n",
       "      <th>Objective Value</th>\n",
       "      <th>Max Integrality Violation</th>\n",
       "      <th>Duality Gap</th>\n",
       "      <th>Reported Runtime (s)</th>\n",
       "      <th>Timeout</th>\n",
       "      <th>Hostname</th>\n",
       "      <th>Run ID</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>genx-4_three_zones_w_policies_slack</td>\n",
       "      <td>3-1h</td>\n",
       "      <td>highs</td>\n",
       "      <td>1.10.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>TO</td>\n",
       "      <td>Timeout</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>3812.844</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>benchmark-instance-z-m37</td>\n",
       "      <td>20250429_090606_benchmark-instance-z-m37</td>\n",
       "      <td>2025-04-29 22:40:55.143181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>genx-6_three_zones_w_multistage-no_uc</td>\n",
       "      <td>3-1h</td>\n",
       "      <td>highs</td>\n",
       "      <td>1.10.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>ok</td>\n",
       "      <td>optimal</td>\n",
       "      <td>170.6828514480003</td>\n",
       "      <td>524.544</td>\n",
       "      <td>16995.001810747806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>169.56626176834106</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>benchmark-instance-z-m37</td>\n",
       "      <td>20250429_090606_benchmark-instance-z-m37</td>\n",
       "      <td>2025-04-30 00:48:26.168300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>pypsa-eur-elec-trex</td>\n",
       "      <td>6-12h</td>\n",
       "      <td>highs</td>\n",
       "      <td>1.10.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>ok</td>\n",
       "      <td>optimal</td>\n",
       "      <td>226.40647792699747</td>\n",
       "      <td>692.944</td>\n",
       "      <td>7243765719.563413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>224.6772541999817</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>benchmark-instance-z-m37</td>\n",
       "      <td>20250429_090606_benchmark-instance-z-m37</td>\n",
       "      <td>2025-04-30 01:05:00.905452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>times-etimeseu-france-elec+heat-co2-multi_stage</td>\n",
       "      <td>1-64ts</td>\n",
       "      <td>highs</td>\n",
       "      <td>1.10.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>ok</td>\n",
       "      <td>optimal</td>\n",
       "      <td>22.216355682998252</td>\n",
       "      <td>365.092</td>\n",
       "      <td>427842.1201974797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.157464027404785</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>benchmark-instance-z-m37</td>\n",
       "      <td>20250429_090606_benchmark-instance-z-m37</td>\n",
       "      <td>2025-04-30 01:13:25.552901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>DCOPF-Carolinas_uc_2M</td>\n",
       "      <td>1-997</td>\n",
       "      <td>highs</td>\n",
       "      <td>1.10.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>ok</td>\n",
       "      <td>optimal</td>\n",
       "      <td>2080.905538397994</td>\n",
       "      <td>2878.12</td>\n",
       "      <td>4463695.700557045</td>\n",
       "      <td>3.502851030676985e-11</td>\n",
       "      <td>9.478984509261144e-05</td>\n",
       "      <td>2079.6019673347478</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>benchmark-instance-z2-m41</td>\n",
       "      <td>20250503_040156_benchmark-instance-z2-m41</td>\n",
       "      <td>2025-05-03 21:11:07.318952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Benchmark    Size Solver  \\\n",
       "45              genx-4_three_zones_w_policies_slack    3-1h  highs   \n",
       "47            genx-6_three_zones_w_multistage-no_uc    3-1h  highs   \n",
       "49                              pypsa-eur-elec-trex   6-12h  highs   \n",
       "51  times-etimeseu-france-elec+heat-co2-multi_stage  1-64ts  highs   \n",
       "86                            DCOPF-Carolinas_uc_2M   1-997  highs   \n",
       "\n",
       "   Solver Version Solver Release Year Status Termination Condition  \\\n",
       "45         1.10.0                2025     TO               Timeout   \n",
       "47         1.10.0                2025     ok               optimal   \n",
       "49         1.10.0                2025     ok               optimal   \n",
       "51         1.10.0                2025     ok               optimal   \n",
       "86         1.10.0                2025     ok               optimal   \n",
       "\n",
       "           Runtime (s) Memory Usage (MB)     Objective Value  \\\n",
       "45              3600.0          3812.844                 NaN   \n",
       "47   170.6828514480003           524.544  16995.001810747806   \n",
       "49  226.40647792699747           692.944   7243765719.563413   \n",
       "51  22.216355682998252           365.092   427842.1201974797   \n",
       "86   2080.905538397994           2878.12   4463695.700557045   \n",
       "\n",
       "   Max Integrality Violation            Duality Gap Reported Runtime (s)  \\\n",
       "45                       NaN                    NaN               3600.0   \n",
       "47                       NaN                    NaN   169.56626176834106   \n",
       "49                       NaN                    NaN    224.6772541999817   \n",
       "51                       NaN                    NaN   21.157464027404785   \n",
       "86     3.502851030676985e-11  9.478984509261144e-05   2079.6019673347478   \n",
       "\n",
       "   Timeout                   Hostname  \\\n",
       "45  3600.0   benchmark-instance-z-m37   \n",
       "47  3600.0   benchmark-instance-z-m37   \n",
       "49  3600.0   benchmark-instance-z-m37   \n",
       "51  3600.0   benchmark-instance-z-m37   \n",
       "86  3600.0  benchmark-instance-z2-m41   \n",
       "\n",
       "                                       Run ID                   Timestamp  \n",
       "45   20250429_090606_benchmark-instance-z-m37  2025-04-29 22:40:55.143181  \n",
       "47   20250429_090606_benchmark-instance-z-m37  2025-04-30 00:48:26.168300  \n",
       "49   20250429_090606_benchmark-instance-z-m37  2025-04-30 01:05:00.905452  \n",
       "51   20250429_090606_benchmark-instance-z-m37  2025-04-30 01:13:25.552901  \n",
       "86  20250503_040156_benchmark-instance-z2-m41  2025-05-03 21:11:07.318952  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load HiGHS runtime data (including HiGHS-hipo if available)\n",
    "highs_data = pd.read_csv(\n",
    "    \"../main_results.csv\",\n",
    "    header=None,\n",
    "    names=[\n",
    "        \"Benchmark\",\n",
    "        \"Size\",\n",
    "        \"Solver\",\n",
    "        \"Solver Version\",\n",
    "        \"Solver Release Year\",\n",
    "        \"Status\",\n",
    "        \"Termination Condition\",\n",
    "        \"Runtime (s)\",\n",
    "        \"Memory Usage (MB)\",\n",
    "        \"Objective Value\",\n",
    "        \"Max Integrality Violation\",\n",
    "        \"Duality Gap\",\n",
    "        \"Reported Runtime (s)\",\n",
    "        \"Timeout\",\n",
    "        \"Hostname\",\n",
    "        \"Run ID\",\n",
    "        \"Timestamp\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Filter for HiGHS 1.10.0 (2025) and HiGHS-hipo successful runs\n",
    "highs_v110 = highs_data[\n",
    "    ((highs_data[\"Solver Version\"] == \"1.10.0\") & (highs_data[\"Solver\"] == \"highs\"))\n",
    "]\n",
    "\n",
    "print(f\"Found {len(highs_v110)} successful HiGHS v1.10/hipo benchmark runs\")\n",
    "print(f\"Solvers included: {highs_v110['Solver'].unique()}\")\n",
    "highs_v110.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime data available for 120 benchmarks\n",
      "Base total runtime (single variant): 525601.61061178 seconds (146.0 hours)\n",
      "Actual total runtime (5 variants): 2628008.0530589 seconds (730.0 hours)\n",
      "Multiplier applied: 5x (running 5 HiGHS variants per benchmark)\n"
     ]
    }
   ],
   "source": [
    "# Create benchmark runtime mapping\n",
    "# IMPORTANT: We multiply runtime by NUM_HIGHS_VARIANTS since each benchmark\n",
    "# is run with 5 different HiGHS variants (highs, highs-hipo-128, highs-hipo-ipm, highs-hipo-32, highs-hipo-64)\n",
    "benchmark_runtimes = {}\n",
    "for _, row in highs_v110.iterrows():\n",
    "    benchmark_key = f\"{row['Benchmark']}-{row['Size']}\"\n",
    "    try:\n",
    "        base_runtime = float(row[\"Runtime (s)\"])\n",
    "        # Multiply by number of variants since we run all variants for each benchmark\n",
    "        if pd.isna(base_runtime):\n",
    "            base_runtime = float(row[\"Timeout\"])\n",
    "        actual_vm_runtime = base_runtime * NUM_HIGHS_VARIANTS\n",
    "        benchmark_runtimes[benchmark_key] = actual_vm_runtime\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row: {row}\")\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "print(f\"Runtime data available for {len(benchmark_runtimes)} benchmarks\")\n",
    "print(\n",
    "    f\"Base total runtime (single variant): {sum(benchmark_runtimes.values()) / NUM_HIGHS_VARIANTS} seconds ({sum(benchmark_runtimes.values()) / NUM_HIGHS_VARIANTS / 3600:.1f} hours)\"\n",
    ")\n",
    "print(\n",
    "    f\"Actual total runtime ({NUM_HIGHS_VARIANTS} variants): {sum(benchmark_runtimes.values())} seconds ({sum(benchmark_runtimes.values()) / 3600:.1f} hours)\"\n",
    ")\n",
    "print(\n",
    "    f\"Multiplier applied: {NUM_HIGHS_VARIANTS}x (running {NUM_HIGHS_VARIANTS} HiGHS variants per benchmark)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Benchmark Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total benchmark instances (from filtered dataset): 120\n",
      "  S: 18\n",
      "  M: 87\n",
      "  L: 15\n",
      "All instances have runtime data from highs_v110\n",
      "Runtime multiplier: 5x (to account for running all HiGHS variants)\n"
     ]
    }
   ],
   "source": [
    "# Load benchmark metadata to get size categories and URLs\n",
    "meta = yaml.safe_load(open(\"../results/metadata.yaml\"))\n",
    "\n",
    "# Create a lookup for metadata\n",
    "metadata_lookup = {}\n",
    "for name, benchmark in meta[\"benchmarks\"].items():\n",
    "    for size_info in benchmark[\"Sizes\"]:\n",
    "        instance_key = f\"{name}-{size_info['Name']}\"\n",
    "        metadata_lookup[instance_key] = size_info\n",
    "\n",
    "benchmarks_by_size = {\"S\": [], \"M\": [], \"L\": []}\n",
    "all_benchmark_instances = []\n",
    "\n",
    "for _, row in highs_v110.iterrows():\n",
    "    instance_key = f\"{row['Benchmark']}-{row['Size']}\"\n",
    "\n",
    "    # Get metadata for this instance\n",
    "    size_info = metadata_lookup.get(instance_key)\n",
    "    if size_info is None:\n",
    "        print(f\"Warning: No metadata found for {instance_key}\")\n",
    "        continue\n",
    "\n",
    "    # Apply variant multiplier to runtime\n",
    "    if pd.isna(row[\"Runtime (s)\"]):\n",
    "        base_runtime = float(row[\"Timeout\"])\n",
    "    else:\n",
    "        base_runtime = float(row[\"Runtime (s)\"])\n",
    "\n",
    "    actual_runtime: float = base_runtime * NUM_HIGHS_VARIANTS\n",
    "\n",
    "    instance = {\n",
    "        \"name\": row[\"Benchmark\"],\n",
    "        \"size_name\": row[\"Size\"],\n",
    "        \"size_category\": size_info[\"Size\"],\n",
    "        \"instance_key\": instance_key,\n",
    "        \"runtime\": actual_runtime,  # Runtime multiplied by number of variants\n",
    "        \"base_runtime\": base_runtime,  # Store original single-variant runtime for reference\n",
    "        \"num_variables\": size_info.get(\"Num. variables\", 0),\n",
    "        \"num_constraints\": size_info.get(\"Num. constraints\", 0),\n",
    "        \"url\": size_info[\"URL\"],\n",
    "    }\n",
    "\n",
    "    benchmarks_by_size[size_info[\"Size\"]].append(instance)\n",
    "    all_benchmark_instances.append(instance)\n",
    "\n",
    "print(\n",
    "    f\"Total benchmark instances (from filtered dataset): {len(all_benchmark_instances)}\"\n",
    ")\n",
    "for size, instances in benchmarks_by_size.items():\n",
    "    print(f\"  {size}: {len(instances)}\")\n",
    "print(\"All instances have runtime data from highs_v110\")\n",
    "print(\n",
    "    f\"Runtime multiplier: {NUM_HIGHS_VARIANTS}x (to account for running all HiGHS variants)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bin Packing Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VMAllocation:\n",
    "    def __init__(self, vm_id: int):\n",
    "        self.vm_id = vm_id\n",
    "        self.benchmarks = []\n",
    "        self.total_runtime = 0.0\n",
    "\n",
    "    def add_benchmark(self, benchmark: dict):\n",
    "        \"\"\"Add benchmark with real runtime data only\"\"\"\n",
    "        if benchmark[\"runtime\"] is None:\n",
    "            raise ValueError(\n",
    "                f\"Benchmark {benchmark['instance_key']} has no runtime data!\"\n",
    "            )\n",
    "\n",
    "        self.benchmarks.append(benchmark)\n",
    "        self.total_runtime += benchmark[\"runtime\"]\n",
    "\n",
    "    def get_total_runtime(self):\n",
    "        return self.total_runtime\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        # For heap operations - compare by total runtime\n",
    "        return self.total_runtime < other.total_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_fit_decreasing(benchmarks: list[dict], num_vms: int) -> list[VMAllocation]:\n",
    "    \"\"\"\n",
    "    First Fit Decreasing bin packing algorithm.\n",
    "    Uses ONLY benchmarks with real runtime data.\n",
    "    \"\"\"\n",
    "    # Filter to only benchmarks with real runtime data\n",
    "    runtime_benchmarks = [b for b in benchmarks if b[\"runtime\"] is not None]\n",
    "    print(\n",
    "        f\"Using {len(runtime_benchmarks)} benchmarks with real runtime data (filtered from {len(benchmarks)} total)\"\n",
    "    )\n",
    "\n",
    "    # Create VMs\n",
    "    vms = [VMAllocation(i) for i in range(num_vms)]\n",
    "\n",
    "    # Sort benchmarks by runtime (descending)\n",
    "    sorted_benchmarks = sorted(\n",
    "        runtime_benchmarks, key=lambda x: x[\"runtime\"], reverse=True\n",
    "    )\n",
    "\n",
    "    # Assign benchmarks to VMs\n",
    "    for benchmark in sorted_benchmarks:\n",
    "        # Find VM with minimum current runtime\n",
    "        min_vm = min(vms, key=lambda vm: vm.total_runtime)\n",
    "        min_vm.add_benchmark(benchmark)\n",
    "\n",
    "    return vms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_processing_time_first(\n",
    "    benchmarks: list[dict], num_vms: int\n",
    ") -> list[VMAllocation]:\n",
    "    \"\"\"\n",
    "    Longest Processing Time First algorithm using a min-heap.\n",
    "    Uses ONLY benchmarks with real runtime data.\n",
    "    \"\"\"\n",
    "    # Filter to only benchmarks with real runtime data\n",
    "    runtime_benchmarks = [b for b in benchmarks if b[\"runtime\"] is not None]\n",
    "    print(\n",
    "        f\"Using {len(runtime_benchmarks)} benchmarks with real runtime data (filtered from {len(benchmarks)} total)\"\n",
    "    )\n",
    "\n",
    "    # Create VMs and initialize heap\n",
    "    vms = [VMAllocation(i) for i in range(num_vms)]\n",
    "    vm_heap = list(vms)  # Min-heap based on total runtime\n",
    "    heapq.heapify(vm_heap)\n",
    "\n",
    "    # Sort benchmarks by runtime (descending)\n",
    "    sorted_benchmarks = sorted(\n",
    "        runtime_benchmarks, key=lambda x: x[\"runtime\"], reverse=True\n",
    "    )\n",
    "\n",
    "    # Assign benchmarks\n",
    "    for benchmark in sorted_benchmarks:\n",
    "        # Get VM with minimum load\n",
    "        min_vm = heapq.heappop(vm_heap)\n",
    "        min_vm.add_benchmark(benchmark)\n",
    "        # Re-insert VM into heap\n",
    "        heapq.heappush(vm_heap, min_vm)\n",
    "\n",
    "    return vms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_partition(\n",
    "    benchmarks: list[dict], num_vms: int, max_runtime_per_vm: float = None\n",
    ") -> list[VMAllocation]:\n",
    "    \"\"\"\n",
    "    Balanced partition algorithm that tries to achieve equal total runtime per VM.\n",
    "    Uses ONLY benchmarks with real runtime data.\n",
    "\n",
    "    If max_runtime_per_vm is set:\n",
    "    - Automatically creates additional VMs if needed to respect the cap\n",
    "    - No VM will exceed max_runtime_per_vm (strictly enforced)\n",
    "\n",
    "    Args:\n",
    "        benchmarks: List of benchmark dictionaries with runtime data\n",
    "        num_vms: Initial number of VMs to create\n",
    "        max_runtime_per_vm: Maximum runtime allowed per VM (in seconds). If None, no limit.\n",
    "    \"\"\"\n",
    "    # Filter to only benchmarks with real runtime data\n",
    "    runtime_benchmarks = [\n",
    "        b for b in benchmarks if b[\"runtime\"] is not None and not pd.isna(b[\"runtime\"])\n",
    "    ]\n",
    "    print(\n",
    "        f\"Using {len(runtime_benchmarks)} benchmarks with real runtime data (filtered from {len(benchmarks)} total)\"\n",
    "    )\n",
    "\n",
    "    if len(runtime_benchmarks) == 0:\n",
    "        return []\n",
    "\n",
    "    # Calculate total runtime and target per VM\n",
    "    total_runtime = sum(b[\"runtime\"] for b in runtime_benchmarks)\n",
    "\n",
    "    # If max_runtime_per_vm is set, ensure we have enough VMs\n",
    "    if max_runtime_per_vm is not None:\n",
    "        min_vms_needed = int(np.ceil(total_runtime / max_runtime_per_vm))\n",
    "        if min_vms_needed > num_vms:\n",
    "            print(\n",
    "                f\"⚠️  WARNING: Initial {num_vms} VMs cannot fit all benchmarks within {max_runtime_per_vm / 3600:.1f}h limit\"\n",
    "            )\n",
    "            print(\n",
    "                f\"   Automatically increasing to {min_vms_needed} VMs to respect runtime cap\"\n",
    "            )\n",
    "            num_vms = min_vms_needed\n",
    "\n",
    "    target_runtime_per_vm = total_runtime / num_vms\n",
    "\n",
    "    print(\n",
    "        f\"Target runtime per VM: {target_runtime_per_vm:.1f} seconds ({target_runtime_per_vm / 3600:.1f} hours)\"\n",
    "    )\n",
    "    if max_runtime_per_vm is not None:\n",
    "        print(\n",
    "            f\"Max runtime per VM (hard cap): {max_runtime_per_vm:.1f} seconds ({max_runtime_per_vm / 3600:.1f} hours)\"\n",
    "        )\n",
    "\n",
    "    # Create initial VMs\n",
    "    vms = [VMAllocation(i) for i in range(num_vms)]\n",
    "\n",
    "    # Sort benchmarks by runtime (descending) - largest first for better bin packing\n",
    "    sorted_benchmarks = sorted(\n",
    "        runtime_benchmarks, key=lambda x: x[\"runtime\"], reverse=True\n",
    "    )\n",
    "\n",
    "    # Assign benchmarks with balance consideration\n",
    "    for benchmark in sorted_benchmarks:\n",
    "        benchmark_runtime = benchmark[\"runtime\"]\n",
    "\n",
    "        # Find VM that would be closest to target after adding this benchmark\n",
    "        best_vm = None\n",
    "        best_score = float(\"inf\")\n",
    "\n",
    "        for vm in vms:\n",
    "            current_runtime = vm.total_runtime\n",
    "            after_runtime = current_runtime + benchmark_runtime\n",
    "\n",
    "            # HARD CAP: Skip if this would exceed max runtime\n",
    "            if max_runtime_per_vm is not None and after_runtime > max_runtime_per_vm:\n",
    "                continue  # This VM cannot take this benchmark\n",
    "\n",
    "            # Score based on deviation from target\n",
    "            score = abs(after_runtime - target_runtime_per_vm)\n",
    "\n",
    "            # Prefer VMs that are under-loaded\n",
    "            if current_runtime < target_runtime_per_vm:\n",
    "                score *= 0.8  # Bonus for under-loaded VMs\n",
    "\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_vm = vm\n",
    "\n",
    "        # If no VM can take this benchmark, create a new one\n",
    "        if best_vm is None:\n",
    "            if (\n",
    "                max_runtime_per_vm is not None\n",
    "                and benchmark_runtime > max_runtime_per_vm\n",
    "            ):\n",
    "                print(\n",
    "                    f\"❌ ERROR: Benchmark {benchmark['instance_key']} runtime ({benchmark_runtime / 3600:.1f}h) exceeds max VM runtime ({max_runtime_per_vm / 3600:.1f}h)!\"\n",
    "                )\n",
    "                print(\n",
    "                    \"   This benchmark CANNOT fit in any VM. Consider increasing MAX_RUNTIME_PER_VM_SECONDS.\"\n",
    "                )\n",
    "                # Still add it to a new VM, but warn the user\n",
    "\n",
    "            print(\n",
    "                f\"⚠️  Creating additional VM #{len(vms)} for benchmark {benchmark['instance_key']} ({benchmark_runtime / 3600:.1f}h)\"\n",
    "            )\n",
    "            best_vm = VMAllocation(len(vms))\n",
    "            vms.append(best_vm)\n",
    "\n",
    "        best_vm.add_benchmark(benchmark)\n",
    "\n",
    "    # Report on VMs created\n",
    "    if len(vms) > num_vms:\n",
    "        print(\n",
    "            f\"✓ Created {len(vms) - num_vms} additional VMs to respect runtime cap (total: {len(vms)} VMs)\"\n",
    "        )\n",
    "\n",
    "    return vms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_allocation(vms: list[VMAllocation], algorithm_name: str):\n",
    "    \"\"\"\n",
    "    Analyze and print statistics for a VM allocation.\n",
    "    \"\"\"\n",
    "    runtimes = [vm.total_runtime for vm in vms]\n",
    "\n",
    "    # Filter out empty VMs (should not happen with real runtime data only)\n",
    "    active_vms = [vm for vm in vms if vm.total_runtime > 0]\n",
    "    active_runtimes = [vm.total_runtime for vm in active_vms]\n",
    "\n",
    "    print(f\"\\n=== {algorithm_name} ===\")\n",
    "    print(f\"Total VMs created: {len(vms)}\")\n",
    "    print(f\"Active VMs (with benchmarks): {len(active_vms)}\")\n",
    "    print(f\"Empty VMs: {len(vms) - len(active_vms)}\")\n",
    "\n",
    "    if len(active_vms) > 0:\n",
    "        print(\n",
    "            f\"Total runtime: {sum(active_runtimes):.1f} seconds ({sum(active_runtimes) / 3600:.1f} hours)\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Average runtime per active VM: {np.mean(active_runtimes):.1f} seconds ({np.mean(active_runtimes) / 3600:.1f} hours)\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Runtime standard deviation: {np.std(active_runtimes):.1f} seconds ({np.std(active_runtimes) / 3600:.1f} hours)\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Min runtime: {min(active_runtimes):.1f} seconds ({min(active_runtimes) / 3600:.1f} hours)\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Max runtime: {max(active_runtimes):.1f} seconds ({max(active_runtimes) / 3600:.1f} hours)\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Runtime ratio (max/min): {max(active_runtimes) / min(active_runtimes):.2f}\"\n",
    "        )\n",
    "\n",
    "        # Efficiency (how balanced the allocation is)\n",
    "        efficiency = 1 - (np.std(active_runtimes) / np.mean(active_runtimes))\n",
    "        print(f\"Load balance efficiency: {efficiency:.3f} (1.0 = perfect balance)\")\n",
    "    else:\n",
    "        print(\"No active VMs found!\")\n",
    "        efficiency = 0\n",
    "\n",
    "    return {\n",
    "        \"algorithm\": algorithm_name,\n",
    "        \"total_runtime\": sum(active_runtimes) if active_vms else 0,\n",
    "        \"std_runtime\": np.std(active_runtimes) if active_vms else 0,\n",
    "        \"max_runtime\": max(active_runtimes) if active_vms else 0,\n",
    "        \"min_runtime\": min(active_runtimes) if active_vms else 0,\n",
    "        \"efficiency\": efficiency,\n",
    "        \"runtimes\": runtimes,\n",
    "        \"active_vms\": len(active_vms),\n",
    "        \"num_vms\": len(vms),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 120 benchmarks with real HiGHS runtime data\n",
      "Excluded 0 benchmarks without runtime data\n",
      "Base total runtime (single HiGHS variant): 146.0 hours\n",
      "Actual total runtime (5 HiGHS variants): 730.0 hours\n",
      "Runtime multiplier: 5x\n",
      "\n",
      "⚙️  Runtime cap enabled: 345600 seconds (96.0 hours) per VM\n",
      "\n",
      "Benchmark separation by size category:\n",
      "  L-size (highmem): 15 benchmarks, 507.9 hours (with 5 variants)\n",
      "  S/M-size (standard): 105 benchmarks, 222.1 hours (with 5 variants)\n",
      "\n",
      "==================================================\n",
      "TESTING L-SIZE BENCHMARKS (HIGHMEM MACHINES)\n",
      "==================================================\n",
      "\n",
      "Testing 2 highmem VMs for L-size benchmarks:\n",
      "Using 15 benchmarks with real runtime data (filtered from 15 total)\n",
      "⚠️  WARNING: Initial 2 VMs cannot fit all benchmarks within 96.0h limit\n",
      "   Automatically increasing to 6 VMs to respect runtime cap\n",
      "Target runtime per VM: 304753.1 seconds (84.7 hours)\n",
      "Max runtime per VM (hard cap): 345600.0 seconds (96.0 hours)\n",
      "⚠️  Creating additional VM #6 for benchmark times-etimeseu-europe-elec+heat-co2-multi_stage-29-64ts (50.0h)\n",
      "⚠️  Creating additional VM #7 for benchmark genx-elec_trex-15-168h (50.0h)\n",
      "✓ Created 2 additional VMs to respect runtime cap (total: 8 VMs)\n",
      "\n",
      "=== L-size Balanced Partition (2 VMs) ===\n",
      "Total VMs created: 8\n",
      "Active VMs (with benchmarks): 8\n",
      "Empty VMs: 0\n",
      "Total runtime: 1828518.8 seconds (507.9 hours)\n",
      "Average runtime per active VM: 228564.8 seconds (63.5 hours)\n",
      "Runtime standard deviation: 62713.1 seconds (17.4 hours)\n",
      "Min runtime: 180000.0 seconds (50.0 hours)\n",
      "Max runtime: 312787.5 seconds (86.9 hours)\n",
      "Runtime ratio (max/min): 1.74\n",
      "Load balance efficiency: 0.726 (1.0 = perfect balance)\n",
      "\n",
      "Testing 3 highmem VMs for L-size benchmarks:\n",
      "Using 15 benchmarks with real runtime data (filtered from 15 total)\n",
      "⚠️  WARNING: Initial 3 VMs cannot fit all benchmarks within 96.0h limit\n",
      "   Automatically increasing to 6 VMs to respect runtime cap\n",
      "Target runtime per VM: 304753.1 seconds (84.7 hours)\n",
      "Max runtime per VM (hard cap): 345600.0 seconds (96.0 hours)\n",
      "⚠️  Creating additional VM #6 for benchmark times-etimeseu-europe-elec+heat-co2-multi_stage-29-64ts (50.0h)\n",
      "⚠️  Creating additional VM #7 for benchmark genx-elec_trex-15-168h (50.0h)\n",
      "✓ Created 2 additional VMs to respect runtime cap (total: 8 VMs)\n",
      "\n",
      "=== L-size Balanced Partition (3 VMs) ===\n",
      "Total VMs created: 8\n",
      "Active VMs (with benchmarks): 8\n",
      "Empty VMs: 0\n",
      "Total runtime: 1828518.8 seconds (507.9 hours)\n",
      "Average runtime per active VM: 228564.8 seconds (63.5 hours)\n",
      "Runtime standard deviation: 62713.1 seconds (17.4 hours)\n",
      "Min runtime: 180000.0 seconds (50.0 hours)\n",
      "Max runtime: 312787.5 seconds (86.9 hours)\n",
      "Runtime ratio (max/min): 1.74\n",
      "Load balance efficiency: 0.726 (1.0 = perfect balance)\n",
      "\n",
      "Testing 4 highmem VMs for L-size benchmarks:\n",
      "Using 15 benchmarks with real runtime data (filtered from 15 total)\n",
      "⚠️  WARNING: Initial 4 VMs cannot fit all benchmarks within 96.0h limit\n",
      "   Automatically increasing to 6 VMs to respect runtime cap\n",
      "Target runtime per VM: 304753.1 seconds (84.7 hours)\n",
      "Max runtime per VM (hard cap): 345600.0 seconds (96.0 hours)\n",
      "⚠️  Creating additional VM #6 for benchmark times-etimeseu-europe-elec+heat-co2-multi_stage-29-64ts (50.0h)\n",
      "⚠️  Creating additional VM #7 for benchmark genx-elec_trex-15-168h (50.0h)\n",
      "✓ Created 2 additional VMs to respect runtime cap (total: 8 VMs)\n",
      "\n",
      "=== L-size Balanced Partition (4 VMs) ===\n",
      "Total VMs created: 8\n",
      "Active VMs (with benchmarks): 8\n",
      "Empty VMs: 0\n",
      "Total runtime: 1828518.8 seconds (507.9 hours)\n",
      "Average runtime per active VM: 228564.8 seconds (63.5 hours)\n",
      "Runtime standard deviation: 62713.1 seconds (17.4 hours)\n",
      "Min runtime: 180000.0 seconds (50.0 hours)\n",
      "Max runtime: 312787.5 seconds (86.9 hours)\n",
      "Runtime ratio (max/min): 1.74\n",
      "Load balance efficiency: 0.726 (1.0 = perfect balance)\n",
      "\n",
      "Testing 5 highmem VMs for L-size benchmarks:\n",
      "Using 15 benchmarks with real runtime data (filtered from 15 total)\n",
      "⚠️  WARNING: Initial 5 VMs cannot fit all benchmarks within 96.0h limit\n",
      "   Automatically increasing to 6 VMs to respect runtime cap\n",
      "Target runtime per VM: 304753.1 seconds (84.7 hours)\n",
      "Max runtime per VM (hard cap): 345600.0 seconds (96.0 hours)\n",
      "⚠️  Creating additional VM #6 for benchmark times-etimeseu-europe-elec+heat-co2-multi_stage-29-64ts (50.0h)\n",
      "⚠️  Creating additional VM #7 for benchmark genx-elec_trex-15-168h (50.0h)\n",
      "✓ Created 2 additional VMs to respect runtime cap (total: 8 VMs)\n",
      "\n",
      "=== L-size Balanced Partition (5 VMs) ===\n",
      "Total VMs created: 8\n",
      "Active VMs (with benchmarks): 8\n",
      "Empty VMs: 0\n",
      "Total runtime: 1828518.8 seconds (507.9 hours)\n",
      "Average runtime per active VM: 228564.8 seconds (63.5 hours)\n",
      "Runtime standard deviation: 62713.1 seconds (17.4 hours)\n",
      "Min runtime: 180000.0 seconds (50.0 hours)\n",
      "Max runtime: 312787.5 seconds (86.9 hours)\n",
      "Runtime ratio (max/min): 1.74\n",
      "Load balance efficiency: 0.726 (1.0 = perfect balance)\n",
      "\n",
      "==================================================\n",
      "TESTING S/M-SIZE BENCHMARKS (STANDARD MACHINES)\n",
      "==================================================\n",
      "\n",
      "Testing 8 standard VMs for S/M-size benchmarks:\n",
      "Using 105 benchmarks with real runtime data (filtered from 105 total)\n",
      "Target runtime per VM: 99936.2 seconds (27.8 hours)\n",
      "Max runtime per VM (hard cap): 345600.0 seconds (96.0 hours)\n",
      "\n",
      "=== S/M-size Balanced Partition (8 VMs) ===\n",
      "Total VMs created: 8\n",
      "Active VMs (with benchmarks): 5\n",
      "Empty VMs: 3\n",
      "Total runtime: 799489.3 seconds (222.1 hours)\n",
      "Average runtime per active VM: 159897.9 seconds (44.4 hours)\n",
      "Runtime standard deviation: 2864.0 seconds (0.8 hours)\n",
      "Min runtime: 154760.9 seconds (43.0 hours)\n",
      "Max runtime: 162000.0 seconds (45.0 hours)\n",
      "Runtime ratio (max/min): 1.05\n",
      "Load balance efficiency: 0.982 (1.0 = perfect balance)\n",
      "\n",
      "Testing 10 standard VMs for S/M-size benchmarks:\n",
      "Using 105 benchmarks with real runtime data (filtered from 105 total)\n",
      "Target runtime per VM: 79948.9 seconds (22.2 hours)\n",
      "Max runtime per VM (hard cap): 345600.0 seconds (96.0 hours)\n",
      "\n",
      "=== S/M-size Balanced Partition (10 VMs) ===\n",
      "Total VMs created: 10\n",
      "Active VMs (with benchmarks): 6\n",
      "Empty VMs: 4\n",
      "Total runtime: 799489.3 seconds (222.1 hours)\n",
      "Average runtime per active VM: 133248.2 seconds (37.0 hours)\n",
      "Runtime standard deviation: 10.2 seconds (0.0 hours)\n",
      "Min runtime: 133238.4 seconds (37.0 hours)\n",
      "Max runtime: 133267.2 seconds (37.0 hours)\n",
      "Runtime ratio (max/min): 1.00\n",
      "Load balance efficiency: 1.000 (1.0 = perfect balance)\n",
      "\n",
      "Testing 12 standard VMs for S/M-size benchmarks:\n",
      "Using 105 benchmarks with real runtime data (filtered from 105 total)\n",
      "Target runtime per VM: 66624.1 seconds (18.5 hours)\n",
      "Max runtime per VM (hard cap): 345600.0 seconds (96.0 hours)\n",
      "\n",
      "=== S/M-size Balanced Partition (12 VMs) ===\n",
      "Total VMs created: 12\n",
      "Active VMs (with benchmarks): 7\n",
      "Empty VMs: 5\n",
      "Total runtime: 799489.3 seconds (222.1 hours)\n",
      "Average runtime per active VM: 114212.8 seconds (31.7 hours)\n",
      "Runtime standard deviation: 6.4 seconds (0.0 hours)\n",
      "Min runtime: 114205.9 seconds (31.7 hours)\n",
      "Max runtime: 114222.8 seconds (31.7 hours)\n",
      "Runtime ratio (max/min): 1.00\n",
      "Load balance efficiency: 1.000 (1.0 = perfect balance)\n",
      "\n",
      "Testing 15 standard VMs for S/M-size benchmarks:\n",
      "Using 105 benchmarks with real runtime data (filtered from 105 total)\n",
      "Target runtime per VM: 53299.3 seconds (14.8 hours)\n",
      "Max runtime per VM (hard cap): 345600.0 seconds (96.0 hours)\n",
      "\n",
      "=== S/M-size Balanced Partition (15 VMs) ===\n",
      "Total VMs created: 15\n",
      "Active VMs (with benchmarks): 10\n",
      "Empty VMs: 5\n",
      "Total runtime: 799489.3 seconds (222.1 hours)\n",
      "Average runtime per active VM: 79948.9 seconds (22.2 hours)\n",
      "Runtime standard deviation: 1074.9 seconds (0.3 hours)\n",
      "Min runtime: 79567.1 seconds (22.1 hours)\n",
      "Max runtime: 83173.4 seconds (23.1 hours)\n",
      "Runtime ratio (max/min): 1.05\n",
      "Load balance efficiency: 0.987 (1.0 = perfect balance)\n"
     ]
    }
   ],
   "source": [
    "# Use ONLY benchmarks that have real runtime data - no estimation!\n",
    "benchmarks_with_runtime = [\n",
    "    b for b in all_benchmark_instances if b[\"runtime\"] is not None\n",
    "]\n",
    "print(f\"Using {len(benchmarks_with_runtime)} benchmarks with real HiGHS runtime data\")\n",
    "print(\n",
    "    f\"Excluded {len(all_benchmark_instances) - len(benchmarks_with_runtime)} benchmarks without runtime data\"\n",
    ")\n",
    "print(\n",
    "    f\"Base total runtime (single HiGHS variant): {sum(b['base_runtime'] for b in benchmarks_with_runtime) / 3600:.1f} hours\"\n",
    ")\n",
    "print(\n",
    "    f\"Actual total runtime ({NUM_HIGHS_VARIANTS} HiGHS variants): {sum(b['runtime'] for b in benchmarks_with_runtime) / 3600:.1f} hours\"\n",
    ")\n",
    "print(f\"Runtime multiplier: {NUM_HIGHS_VARIANTS}x\")\n",
    "\n",
    "if MAX_RUNTIME_PER_VM_SECONDS is not None:\n",
    "    print(\n",
    "        f\"\\n⚙️  Runtime cap enabled: {MAX_RUNTIME_PER_VM_SECONDS} seconds ({MAX_RUNTIME_PER_VM_SECONDS / 3600:.1f} hours) per VM\"\n",
    "    )\n",
    "else:\n",
    "    print(\"\\n⚙️  No runtime cap configured (unlimited)\")\n",
    "\n",
    "# Separate L-size benchmarks for highmem machines\n",
    "l_size_benchmarks = [b for b in benchmarks_with_runtime if b[\"size_category\"] == \"L\"]\n",
    "non_l_benchmarks = [b for b in benchmarks_with_runtime if b[\"size_category\"] != \"L\"]\n",
    "\n",
    "print(\"\\nBenchmark separation by size category:\")\n",
    "print(\n",
    "    f\"  L-size (highmem): {len(l_size_benchmarks)} benchmarks, {sum(b['runtime'] for b in l_size_benchmarks) / 3600:.1f} hours (with {NUM_HIGHS_VARIANTS} variants)\"\n",
    ")\n",
    "print(\n",
    "    f\"  S/M-size (standard): {len(non_l_benchmarks)} benchmarks, {sum(b['runtime'] for b in non_l_benchmarks) / 3600:.1f} hours (with {NUM_HIGHS_VARIANTS} variants)\"\n",
    ")\n",
    "\n",
    "# Test different numbers of VMs for each category\n",
    "results = []\n",
    "\n",
    "# L-size benchmarks (fewer VMs since they need highmem)\n",
    "print(f\"\\n{'=' * 50}\")\n",
    "print(\"TESTING L-SIZE BENCHMARKS (HIGHMEM MACHINES)\")\n",
    "print(f\"{'=' * 50}\")\n",
    "\n",
    "l_vm_options = [2, 3, 4, 5] if len(l_size_benchmarks) > 0 else [1]\n",
    "for num_vms in l_vm_options:\n",
    "    if len(l_size_benchmarks) == 0:\n",
    "        print(\"No L-size benchmarks with runtime data\")\n",
    "        break\n",
    "\n",
    "    print(f\"\\nTesting {num_vms} highmem VMs for L-size benchmarks:\")\n",
    "\n",
    "    bp_vms = balanced_partition(l_size_benchmarks, num_vms, MAX_RUNTIME_PER_VM_SECONDS)\n",
    "    bp_result = analyze_allocation(bp_vms, f\"L-size Balanced Partition ({num_vms} VMs)\")\n",
    "    bp_result[\"num_vms\"] = num_vms\n",
    "    bp_result[\"size_category\"] = \"L\"\n",
    "    results.append(bp_result)\n",
    "\n",
    "# S/M-size benchmarks (more VMs with standard machines)\n",
    "print(f\"\\n{'=' * 50}\")\n",
    "print(\"TESTING S/M-SIZE BENCHMARKS (STANDARD MACHINES)\")\n",
    "print(f\"{'=' * 50}\")\n",
    "\n",
    "sm_vm_options = [8, 10, 12, 15]\n",
    "for num_vms in sm_vm_options:\n",
    "    if len(non_l_benchmarks) == 0:\n",
    "        print(\"No S/M-size benchmarks with runtime data\")\n",
    "        break\n",
    "\n",
    "    print(f\"\\nTesting {num_vms} standard VMs for S/M-size benchmarks:\")\n",
    "\n",
    "    bp_vms = balanced_partition(non_l_benchmarks, num_vms, MAX_RUNTIME_PER_VM_SECONDS)\n",
    "    bp_result = analyze_allocation(\n",
    "        bp_vms, f\"S/M-size Balanced Partition ({num_vms} VMs)\"\n",
    "    )\n",
    "    bp_result[\"num_vms\"] = num_vms\n",
    "    bp_result[\"size_category\"] = \"S/M\"\n",
    "    results.append(bp_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n================================================================================\n",
      "ALGORITHM COMPARISON SUMMARY\n",
      "================================================================================\n",
      "\\nSize   VM Count  Algorithm                 Efficiency   Max Runtime (h) Std Dev (h) \n",
      "-------------------------------------------------------------------------------------\n",
      "L      2         L-size Balanced Partition 0.726         86.9             17.4\n",
      "L      3         L-size Balanced Partition 0.726         86.9             17.4\n",
      "L      4         L-size Balanced Partition 0.726         86.9             17.4\n",
      "L      5         L-size Balanced Partition 0.726         86.9             17.4\n",
      "S/M    8         S/M-size Balanced Partition 0.982         45.0             0.8\n",
      "S/M    10        S/M-size Balanced Partition 1.000         37.0             0.0\n",
      "S/M    12        S/M-size Balanced Partition 1.000         31.7             0.0\n",
      "S/M    15        S/M-size Balanced Partition 0.987         23.1             0.3\n",
      "\\n================================================================================\n",
      "BEST CONFIGURATIONS:\n",
      "================================================================================\n",
      "Best L-size (highmem): 2 VMs (efficiency: 0.726)\n",
      "Best S/M-size (standard): 12 VMs (efficiency: 1.000)\n",
      "\\nTotal deployment: 14 VMs (2 highmem + 12 standard)\n",
      "Average efficiency: 0.863\n"
     ]
    }
   ],
   "source": [
    "# Print summary comparison table\n",
    "print(\"\\\\n\" + \"=\" * 80)\n",
    "print(\"ALGORITHM COMPARISON SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Separate results by size category\n",
    "l_results = (\n",
    "    df_results[df_results[\"size_category\"] == \"L\"]\n",
    "    if \"size_category\" in df_results.columns\n",
    "    else pd.DataFrame()\n",
    ")\n",
    "sm_results = (\n",
    "    df_results[df_results[\"size_category\"] == \"S/M\"]\n",
    "    if \"size_category\" in df_results.columns\n",
    "    else df_results\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"\\\\n{'Size':<6} {'VM Count':<9} {'Algorithm':<25} {'Efficiency':<12} {'Max Runtime (h)':<15} {'Std Dev (h)':<12}\"\n",
    ")\n",
    "print(\"-\" * 85)\n",
    "\n",
    "for _, row in df_results.iterrows():\n",
    "    size_cat = row.get(\"size_category\", \"Mixed\")\n",
    "    alg_name = row[\"algorithm\"].split(\"(\")[0].strip()\n",
    "    print(\n",
    "        f\"{size_cat:<6} {row['num_vms']:<9} {alg_name:<25} \"\n",
    "        f\"{row['efficiency']:.3f}{'':8} {row['max_runtime'] / 3600:.1f}{'':12} \"\n",
    "        f\"{row['std_runtime'] / 3600:.1f}\"\n",
    "    )\n",
    "\n",
    "# Find best configurations for each size category\n",
    "print(f\"\\\\n{'=' * 80}\")\n",
    "print(\"BEST CONFIGURATIONS:\")\n",
    "print(f\"{'=' * 80}\")\n",
    "\n",
    "if len(l_results) > 0:\n",
    "    best_l = l_results.loc[l_results[\"efficiency\"].idxmax()]\n",
    "    print(\n",
    "        f\"Best L-size (highmem): {best_l['num_vms']} VMs (efficiency: {best_l['efficiency']:.3f})\"\n",
    "    )\n",
    "\n",
    "if len(sm_results) > 0:\n",
    "    best_sm = sm_results.loc[sm_results[\"efficiency\"].idxmax()]\n",
    "    print(\n",
    "        f\"Best S/M-size (standard): {best_sm['num_vms']} VMs (efficiency: {best_sm['efficiency']:.3f})\"\n",
    "    )\n",
    "\n",
    "# Calculate total deployment\n",
    "if len(l_results) > 0 and len(sm_results) > 0:\n",
    "    total_vms = best_l[\"num_vms\"] + best_sm[\"num_vms\"]\n",
    "    total_efficiency = (best_l[\"efficiency\"] + best_sm[\"efficiency\"]) / 2\n",
    "    print(\n",
    "        f\"\\\\nTotal deployment: {total_vms} VMs ({best_l['num_vms']} highmem + {best_sm['num_vms']} standard)\"\n",
    "    )\n",
    "    print(f\"Average efficiency: {total_efficiency:.3f}\")\n",
    "elif len(sm_results) > 0:\n",
    "    print(f\"\\\\nTotal deployment: {best_sm['num_vms']} standard VMs only\")\n",
    "    print(f\"Efficiency: {best_sm['efficiency']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Optimal Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating optimal allocations with size-based machine separation...\n",
      "Runtime cap: 345600s (96.0h) per VM\n",
      "\n",
      "L-size benchmarks: 2 highmem VMs\n",
      "Efficiency: 0.726\n",
      "Max VM runtime: 86.9 hours\n",
      "Using 15 benchmarks with real runtime data (filtered from 15 total)\n",
      "⚠️  WARNING: Initial 2 VMs cannot fit all benchmarks within 96.0h limit\n",
      "   Automatically increasing to 6 VMs to respect runtime cap\n",
      "Target runtime per VM: 304753.1 seconds (84.7 hours)\n",
      "Max runtime per VM (hard cap): 345600.0 seconds (96.0 hours)\n",
      "⚠️  Creating additional VM #6 for benchmark times-etimeseu-europe-elec+heat-co2-multi_stage-29-64ts (50.0h)\n",
      "⚠️  Creating additional VM #7 for benchmark genx-elec_trex-15-168h (50.0h)\n",
      "✓ Created 2 additional VMs to respect runtime cap (total: 8 VMs)\n",
      "\n",
      "=== Final L-size Allocation - Highmem ===\n",
      "Total VMs created: 8\n",
      "Active VMs (with benchmarks): 8\n",
      "Empty VMs: 0\n",
      "Total runtime: 1828518.8 seconds (507.9 hours)\n",
      "Average runtime per active VM: 228564.8 seconds (63.5 hours)\n",
      "Runtime standard deviation: 62713.1 seconds (17.4 hours)\n",
      "Min runtime: 180000.0 seconds (50.0 hours)\n",
      "Max runtime: 312787.5 seconds (86.9 hours)\n",
      "Runtime ratio (max/min): 1.74\n",
      "Load balance efficiency: 0.726 (1.0 = perfect balance)\n",
      "\n",
      "S/M-size benchmarks: 12 standard VMs\n",
      "Efficiency: 1.000\n",
      "Max VM runtime: 31.7 hours\n",
      "Using 105 benchmarks with real runtime data (filtered from 105 total)\n",
      "Target runtime per VM: 66624.1 seconds (18.5 hours)\n",
      "Max runtime per VM (hard cap): 345600.0 seconds (96.0 hours)\n",
      "\n",
      "=== Final S/M-size Allocation - Standard ===\n",
      "Total VMs created: 12\n",
      "Active VMs (with benchmarks): 7\n",
      "Empty VMs: 5\n",
      "Total runtime: 799489.3 seconds (222.1 hours)\n",
      "Average runtime per active VM: 114212.8 seconds (31.7 hours)\n",
      "Runtime standard deviation: 6.4 seconds (0.0 hours)\n",
      "Min runtime: 114205.9 seconds (31.7 hours)\n",
      "Max runtime: 114222.8 seconds (31.7 hours)\n",
      "Runtime ratio (max/min): 1.00\n",
      "Load balance efficiency: 1.000 (1.0 = perfect balance)\n",
      "\n",
      "============================================================\n",
      "FINAL ALLOCATION SUMMARY\n",
      "============================================================\n",
      "Total VMs: 20\n",
      "  - Highmem VMs (L-size): 8\n",
      "  - Standard VMs (S/M-size): 12\n",
      "Total allocated runtime: 730.0 hours\n",
      "Machine separation ensures optimal resource utilization\n"
     ]
    }
   ],
   "source": [
    "# Generate optimal allocations for both size categories\n",
    "print(\"\\n\\nGenerating optimal allocations with size-based machine separation...\")\n",
    "\n",
    "if MAX_RUNTIME_PER_VM_SECONDS is not None:\n",
    "    print(\n",
    "        f\"Runtime cap: {MAX_RUNTIME_PER_VM_SECONDS}s ({MAX_RUNTIME_PER_VM_SECONDS / 3600:.1f}h) per VM\"\n",
    "    )\n",
    "\n",
    "optimal_l_vms = []\n",
    "optimal_sm_vms = []\n",
    "best_l_result = None\n",
    "best_sm_result = None\n",
    "\n",
    "# Generate L-size allocation (highmem machines)\n",
    "if len(l_results) > 0:\n",
    "    best_l_result = l_results.loc[l_results[\"efficiency\"].idxmax()]\n",
    "    optimal_l_num_vms = best_l_result[\"num_vms\"]\n",
    "\n",
    "    print(f\"\\nL-size benchmarks: {optimal_l_num_vms} highmem VMs\")\n",
    "    print(f\"Efficiency: {best_l_result['efficiency']:.3f}\")\n",
    "    print(f\"Max VM runtime: {best_l_result['max_runtime'] / 3600:.1f} hours\")\n",
    "\n",
    "    optimal_l_vms = balanced_partition(\n",
    "        l_size_benchmarks, optimal_l_num_vms, MAX_RUNTIME_PER_VM_SECONDS\n",
    "    )\n",
    "    l_final_result = analyze_allocation(\n",
    "        optimal_l_vms, \"Final L-size Allocation - Highmem\"\n",
    "    )\n",
    "\n",
    "# Generate S/M-size allocation (standard machines)\n",
    "if len(sm_results) > 0:\n",
    "    best_sm_result = sm_results.loc[sm_results[\"efficiency\"].idxmax()]\n",
    "    optimal_sm_num_vms = best_sm_result[\"num_vms\"]\n",
    "\n",
    "    print(f\"\\nS/M-size benchmarks: {optimal_sm_num_vms} standard VMs\")\n",
    "    print(f\"Efficiency: {best_sm_result['efficiency']:.3f}\")\n",
    "    print(f\"Max VM runtime: {best_sm_result['max_runtime'] / 3600:.1f} hours\")\n",
    "\n",
    "    optimal_sm_vms = balanced_partition(\n",
    "        non_l_benchmarks, optimal_sm_num_vms, MAX_RUNTIME_PER_VM_SECONDS\n",
    "    )\n",
    "    sm_final_result = analyze_allocation(\n",
    "        optimal_sm_vms, \"Final S/M-size Allocation - Standard\"\n",
    "    )\n",
    "\n",
    "# Combined summary\n",
    "total_vms = len(optimal_l_vms) + len(optimal_sm_vms)\n",
    "total_runtime = sum(vm.total_runtime for vm in optimal_l_vms + optimal_sm_vms)\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"FINAL ALLOCATION SUMMARY\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(f\"Total VMs: {total_vms}\")\n",
    "print(f\"  - Highmem VMs (L-size): {len(optimal_l_vms)}\")\n",
    "print(f\"  - Standard VMs (S/M-size): {len(optimal_sm_vms)}\")\n",
    "print(f\"Total allocated runtime: {total_runtime / 3600:.1f} hours\")\n",
    "print(\"Machine separation ensures optimal resource utilization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting 8 highmem VMs and 7 standard VMs (skipping empty VMs)\n",
      "\n",
      "Exported highmem-vm-00.yaml: 2 L-size benchmarks, 86.9h runtime\n",
      "Exported highmem-vm-01.yaml: 4 L-size benchmarks, 85.6h runtime\n",
      "Exported highmem-vm-02.yaml: 4 L-size benchmarks, 85.5h runtime\n",
      "Exported highmem-vm-03.yaml: 1 L-size benchmarks, 50.0h runtime\n",
      "Exported highmem-vm-04.yaml: 1 L-size benchmarks, 50.0h runtime\n",
      "Exported highmem-vm-05.yaml: 1 L-size benchmarks, 50.0h runtime\n",
      "Exported highmem-vm-06.yaml: 1 L-size benchmarks, 50.0h runtime\n",
      "Exported highmem-vm-07.yaml: 1 L-size benchmarks, 50.0h runtime\n",
      "Exported standard-00.yaml: 15 S/M-size benchmarks, 31.7h runtime\n",
      "Exported standard-01.yaml: 15 S/M-size benchmarks, 31.7h runtime\n",
      "Exported standard-02.yaml: 15 S/M-size benchmarks, 31.7h runtime\n",
      "Exported standard-03.yaml: 14 S/M-size benchmarks, 31.7h runtime\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported standard-04.yaml: 18 S/M-size benchmarks, 31.7h runtime\n",
      "Exported standard-05.yaml: 14 S/M-size benchmarks, 31.7h runtime\n",
      "Exported standard-06.yaml: 14 S/M-size benchmarks, 31.7h runtime\n",
      "\n",
      "======================================================================\n",
      "Configuration files written to ../infrastructure/benchmarks/runtime_optimized/\n",
      "Total VMs exported: 15 (skipped 5 empty VMs)\n",
      "  - Highmem VMs: 8\n",
      "  - Standard VMs: 7\n",
      "Total benchmarks exported: 120\n",
      "Total runtime allocated: 730.0 hours\n",
      "\n",
      "MACHINE SEPARATION POLICY:\n",
      "  - L-size benchmarks → c4-highmem-8 (high memory for large problems)\n",
      "  - S/M-size benchmarks → c4-standard-2 (cost-effective for smaller problems)\n",
      "\n",
      "RUNTIME CAP: 96.0h (4.0 days) per VM\n",
      "\n",
      "BENCHMARK ORDERING: Smallest runtime first (order preserved in YAML)\n",
      "NOTE: Only benchmarks with real HiGHS runtime data were included.\n"
     ]
    }
   ],
   "source": [
    "# Export the allocation to YAML files for infrastructure\n",
    "# NOTE: This exports ONLY benchmarks with real runtime data, separated by size category\n",
    "# ONLY exports VMs that have benchmarks assigned (skips empty VMs)\n",
    "# Benchmarks are sorted SMALLEST FIRST so they run in that order on each VM\n",
    "output_dir = Path(\"../infrastructure/benchmarks/runtime_optimized\")\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Clear existing files\n",
    "for file in output_dir.glob(\"*.yaml\"):\n",
    "    file.unlink()\n",
    "\n",
    "exported_vms = 0\n",
    "total_benchmarks_exported = 0\n",
    "\n",
    "# Filter to only VMs with benchmarks\n",
    "active_l_vms = [vm for vm in optimal_l_vms if vm.benchmarks]\n",
    "active_sm_vms = [vm for vm in optimal_sm_vms if vm.benchmarks]\n",
    "\n",
    "print(\n",
    "    f\"Exporting {len(active_l_vms)} highmem VMs and {len(active_sm_vms)} standard VMs (skipping empty VMs)\\n\"\n",
    ")\n",
    "\n",
    "# Export L-size VMs (highmem machines)\n",
    "for vm_idx, vm in enumerate(active_l_vms):\n",
    "    # L-size benchmarks always get highmem machines\n",
    "    machine_type = \"c4-highmem-8\"\n",
    "    years = [2025]  # Include highs-hipo for L benchmarks\n",
    "\n",
    "    # Sort benchmarks by runtime (SMALLEST FIRST) so they run in order\n",
    "    sorted_benchmarks = sorted(vm.benchmarks, key=lambda b: b[\"runtime\"])\n",
    "\n",
    "    # Create benchmark structure with runtime metadata\n",
    "    benchmarks_dict = {}\n",
    "    benchmark_runtimes = {}  # Track total runtime per benchmark\n",
    "\n",
    "    for benchmark in sorted_benchmarks:  # Use sorted list\n",
    "        benchmark_name = benchmark[\"name\"]\n",
    "        if benchmark_name not in benchmarks_dict:\n",
    "            benchmarks_dict[benchmark_name] = {\"Sizes\": []}\n",
    "            benchmark_runtimes[benchmark_name] = 0.0\n",
    "\n",
    "        size_entry = {\n",
    "            \"Name\": benchmark[\"size_name\"],\n",
    "            \"Size\": benchmark[\"size_category\"],\n",
    "            \"URL\": benchmark[\"url\"],\n",
    "            \"_runtime_s\": round(benchmark[\"runtime\"], 2),\n",
    "            \"_base_runtime_s\": round(benchmark[\"base_runtime\"], 2),\n",
    "        }\n",
    "        benchmarks_dict[benchmark_name][\"Sizes\"].append(size_entry)\n",
    "        benchmark_runtimes[benchmark_name] += benchmark[\"runtime\"]\n",
    "\n",
    "    # Add total runtime for each benchmark\n",
    "    for benchmark_name in benchmarks_dict:\n",
    "        benchmarks_dict[benchmark_name][\"_runtime_s\"] = round(\n",
    "            benchmark_runtimes[benchmark_name], 2\n",
    "        )\n",
    "\n",
    "    # Create YAML content with total runtime metadata\n",
    "    yaml_content = {\n",
    "        \"machine-type\": machine_type,\n",
    "        \"years\": years,\n",
    "        \"_total_runtime_s\": round(vm.total_runtime, 2),\n",
    "        \"_total_runtime_h\": round(vm.total_runtime / 3600, 2),\n",
    "        \"_max_runtime_cap_h\": MAX_RUNTIME_PER_VM_SECONDS / 3600\n",
    "        if MAX_RUNTIME_PER_VM_SECONDS\n",
    "        else None,\n",
    "        \"_num_benchmarks\": len(vm.benchmarks),\n",
    "        \"_note\": \"Benchmarks sorted by runtime (smallest first). YAML dict order is preserved in Python 3.7+.\",\n",
    "        \"benchmarks\": benchmarks_dict,\n",
    "    }\n",
    "\n",
    "    # Write to file\n",
    "    filename = f\"highmem-vm-{vm_idx:02d}.yaml\"\n",
    "    with open(output_dir / filename, \"w\") as f:\n",
    "        yaml.safe_dump(yaml_content, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "    print(\n",
    "        f\"Exported {filename}: {len(vm.benchmarks)} L-size benchmarks, \"\n",
    "        f\"{vm.total_runtime / 3600:.1f}h runtime\"\n",
    "    )\n",
    "\n",
    "    total_benchmarks_exported += len(vm.benchmarks)\n",
    "\n",
    "# Export S/M-size VMs (standard machines)\n",
    "for vm_idx, vm in enumerate(active_sm_vms):\n",
    "    # S/M-size benchmarks get standard machines\n",
    "    machine_type = \"c4-standard-2\"\n",
    "    years = [2025]\n",
    "\n",
    "    # Sort benchmarks by runtime (SMALLEST FIRST) so they run in order\n",
    "    sorted_benchmarks = sorted(vm.benchmarks, key=lambda b: b[\"runtime\"])\n",
    "\n",
    "    # Create benchmark structure with runtime metadata\n",
    "    benchmarks_dict = {}\n",
    "    benchmark_runtimes = {}  # Track total runtime per benchmark\n",
    "\n",
    "    for benchmark in sorted_benchmarks:  # Use sorted list\n",
    "        benchmark_name = benchmark[\"name\"]\n",
    "        if benchmark_name not in benchmarks_dict:\n",
    "            benchmarks_dict[benchmark_name] = {\"Sizes\": []}\n",
    "            benchmark_runtimes[benchmark_name] = 0.0\n",
    "\n",
    "        size_entry = {\n",
    "            \"Name\": benchmark[\"size_name\"],\n",
    "            \"Size\": benchmark[\"size_category\"],\n",
    "            \"URL\": benchmark[\"url\"],\n",
    "            \"_runtime_s\": round(benchmark[\"runtime\"], 2),\n",
    "            \"_base_runtime_s\": round(benchmark[\"base_runtime\"], 2),\n",
    "        }\n",
    "        benchmarks_dict[benchmark_name][\"Sizes\"].append(size_entry)\n",
    "        benchmark_runtimes[benchmark_name] += benchmark[\"runtime\"]\n",
    "\n",
    "    # Add total runtime for each benchmark\n",
    "    for benchmark_name in benchmarks_dict:\n",
    "        benchmarks_dict[benchmark_name][\"_runtime_s\"] = round(\n",
    "            benchmark_runtimes[benchmark_name], 2\n",
    "        )\n",
    "\n",
    "    # Create YAML content with total runtime metadata\n",
    "    yaml_content = {\n",
    "        \"machine-type\": machine_type,\n",
    "        \"years\": years,\n",
    "        \"_total_runtime_s\": round(vm.total_runtime, 2),\n",
    "        \"_total_runtime_h\": round(vm.total_runtime / 3600, 2),\n",
    "        \"_max_runtime_cap_h\": MAX_RUNTIME_PER_VM_SECONDS / 3600\n",
    "        if MAX_RUNTIME_PER_VM_SECONDS\n",
    "        else None,\n",
    "        \"_num_benchmarks\": len(vm.benchmarks),\n",
    "        \"_note\": \"Benchmarks sorted by runtime (smallest first). YAML dict order is preserved in Python 3.7+.\",\n",
    "        \"benchmarks\": benchmarks_dict,\n",
    "    }\n",
    "\n",
    "    # Write to file\n",
    "    filename = f\"standard-{vm_idx:02d}.yaml\"\n",
    "    with open(output_dir / filename, \"w\") as f:\n",
    "        yaml.safe_dump(yaml_content, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "    print(\n",
    "        f\"Exported {filename}: {len(vm.benchmarks)} S/M-size benchmarks, \"\n",
    "        f\"{vm.total_runtime / 3600:.1f}h runtime\"\n",
    "    )\n",
    "\n",
    "    total_benchmarks_exported += len(vm.benchmarks)\n",
    "\n",
    "total_exported_vms = len(active_l_vms) + len(active_sm_vms)\n",
    "\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(f\"Configuration files written to {output_dir}/\")\n",
    "print(\n",
    "    f\"Total VMs exported: {total_exported_vms} (skipped {len(optimal_l_vms) + len(optimal_sm_vms) - total_exported_vms} empty VMs)\"\n",
    ")\n",
    "print(f\"  - Highmem VMs: {len(active_l_vms)}\")\n",
    "print(f\"  - Standard VMs: {len(active_sm_vms)}\")\n",
    "print(f\"Total benchmarks exported: {total_benchmarks_exported}\")\n",
    "print(\n",
    "    f\"Total runtime allocated: {sum(vm.total_runtime for vm in active_l_vms + active_sm_vms) / 3600:.1f} hours\"\n",
    ")\n",
    "print(\"\\nMACHINE SEPARATION POLICY:\")\n",
    "print(\"  - L-size benchmarks → c4-highmem-8 (high memory for large problems)\")\n",
    "print(\"  - S/M-size benchmarks → c4-standard-2 (cost-effective for smaller problems)\")\n",
    "print(\n",
    "    f\"\\nRUNTIME CAP: {MAX_RUNTIME_PER_VM_SECONDS / 3600:.1f}h ({MAX_RUNTIME_PER_VM_SECONDS / (24 * 3600):.1f} days) per VM\"\n",
    "    if MAX_RUNTIME_PER_VM_SECONDS\n",
    "    else \"\\nNo runtime cap configured\"\n",
    ")\n",
    "print(\"\\nBENCHMARK ORDERING: Smallest runtime first (order preserved in YAML)\")\n",
    "print(\"NOTE: Only benchmarks with real HiGHS runtime data were included.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benchmark-tests",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
