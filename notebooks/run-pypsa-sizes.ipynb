{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99b298f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "from runner.utils import (\n",
    "    allocate_benchmarks,\n",
    "    create_benchmark_campaign,\n",
    "    load_benchmark_metadata,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e00fe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If a util function was modified, use this cell to reload it without having to restart the kernel\n",
    "%run ../runner/utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20181a6d",
   "metadata": {},
   "source": [
    "## Create benchmark campaign(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d56dd7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarks_df = load_benchmark_metadata()\n",
    "benchs_to_run = benchmarks_df[\n",
    "    (benchmarks_df[\"Benchmark\"] == \"pypsa-de-elec\")\n",
    "    & (benchmarks_df[\"Instance\"].str.endswith(\"-1h\"))\n",
    "]\n",
    "# NOTE: picking only even num of nodes >= 6 to save costs\n",
    "benchs_to_run = benchs_to_run[\n",
    "    benchs_to_run[\"Instance\"].map(\n",
    "        lambda i: (lambda n: n >= 6 and n % 2 == 0)(int(i.split(\"-\")[0]))\n",
    "    )\n",
    "]\n",
    "len(benchs_to_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce18b011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated. Estimated runtime: 0.0h\n",
      "  VM 00: 1 instances, 0.0h\n",
      "  VM 01: 1 instances, 0.0h\n",
      "  VM 02: 1 instances, 0.0h\n",
      "  VM 03: 1 instances, 0.0h\n",
      "  VM 04: 1 instances, 0.0h\n",
      "  VM 05: 1 instances, 0.0h\n",
      "  VM 06: 1 instances, 0.0h\n",
      "  VM 07: 1 instances, 0.0h\n",
      "  VM 08: 1 instances, 0.0h\n",
      "  VM 09: 1 instances, 0.0h\n",
      "  VM 10: 1 instances, 0.0h\n",
      "Created directory and files in ../infrastructure/benchmarks/20260211-all-pypsa-de-sizes\n",
      "Run this campaign from the infrastructure/ directory using the command:\n",
      "tofu apply -var-file benchmarks/20260211-all-pypsa-de-sizes/run.tfvars -state=states/20260211-all-pypsa-de-sizes.tfstate\n"
     ]
    }
   ],
   "source": [
    "# Create campaign: 1 instance per VM, latest solvers only (because I marked all as Ls in the metadata)\n",
    "\n",
    "benchs_to_run.loc[:, \"Num. variables\"] = 1  # Dummy value to run 1 instance per VM\n",
    "vm_yamls = allocate_benchmarks(\n",
    "    benchs_to_run,\n",
    "    \"Num. variables\",\n",
    "    len(benchs_to_run),\n",
    "    machine_type=\"c4-standard-8\",  # NOTE: picked a smaller machine size to save costs!\n",
    "    timeout_seconds=24 * 60 * 60,\n",
    "    solvers=\"cbc gurobi highs-hipo highs-ipm highs\",  # NOTE: skipped SCIP since it's not built for LPs\n",
    ")\n",
    "\n",
    "# # Use a different zone for some instances to avoid exceeding CPU quota\n",
    "# for y in vm_yamls:\n",
    "#     if int(y['benchmarks']['pypsa-de-elec']['Sizes'][0]['Name'].split('-')[0]) >= 20:\n",
    "#         print(y['benchmarks']['pypsa-de-elec']['Sizes'][0]['Name'])\n",
    "#         y['zone'] = 'us-east4-a'\n",
    "\n",
    "create_benchmark_campaign(\n",
    "    \"20260211-all-pypsa-de-sizes\",\n",
    "    \"all-pypsa-de-sizes\",\n",
    "    vm_yamls,\n",
    "    years='[\"2024\", \"2025\"]',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f102f4e",
   "metadata": {},
   "source": [
    "NOTE: to run tofu using service key, I used the env var method: `export GOOGLE_APPLICATION_CREDENTIALS=$(realpath ../orchestrator-gcp-key.json)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fc8247",
   "metadata": {},
   "source": [
    "## Monitor runs\n",
    "\n",
    "To view running VMs:\n",
    "```\n",
    "gcloud compute instances list | sort | tee /dev/tty | grep benchmark-instance | grep -i running | wc -l\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d13cd15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
