name: CI

on:
  # Triggers the workflow on push or pull request events but only for the main branch
  push:
    branches: [main]
  pull_request:
    branches: [main]
  # Allows you to run this workflow manually from the Actions tab
  # workflow_dispatch:

jobs:
  CI:
    runs-on: ubuntu-latest

    env:
      PY_VERSION: "3.12"
      NEXT_PUBLIC_RECAPTCHA_SITE_KEY: ${{ secrets.NEXT_PUBLIC_RECAPTCHA_SITE_KEY }}
      NEXT_PUBLIC_EMAILJS_SERVICE_ID: ${{ secrets.NEXT_PUBLIC_EMAILJS_SERVICE_ID }}
      NEXT_PUBLIC_EMAILJS_TEMPLATE_ID: ${{ secrets.NEXT_PUBLIC_EMAILJS_TEMPLATE_ID }}
      NEXT_PUBLIC_EMAILJS_PUBLIC_KEY: ${{ secrets.NEXT_PUBLIC_EMAILJS_PUBLIC_KEY }}
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PY_VERSION }}

      - name: Install dependencies
        run: |
          pip install --upgrade pip pre-commit
          pip install -r website/requirements.txt

      - name: Check code formatting
        run: |
          pre-commit install
          pre-commit run --all-files

      - name: Check benchmark metadata and results
        run: |
          python benchmarks/merge_metadata.py
          if git diff --quiet; then
            echo "git diff is empty, metadata must be up to date"
          else
            git diff
            printf "ERROR: git diff non empty, metadata needs updating, please run the following command:\npython benchmarks/merge_metadata.py"
            exit 1
          fi
          python tests/validate_urls.py
          if git diff --quiet; then
            echo "git diff is empty, benchmark URLs conform to expected format"
          else
            git diff
            printf "ERROR: benchmark URLs do not match expected format, please run the following command:\npython tests/validate_urls.py"
            exit 1
          fi
          python tests/validate_results.py

      - name: Run Streamlit App Action
        uses: streamlit/streamlit-app-action@v0.0.3
        with:
            app-path: website/app.py

      - name: Set FORK_PR environment variable
        if: ${{ github.event.pull_request.head.repo.fork == true && github.event_name == 'pull_request' }}
        run: echo "FORK_PR=true" >> $GITHUB_ENV

      - name: Check Next.js build
        run: |
          echo "Checking Next.js build..."
          if [ -d "website-nextjs" ] && [ -f "website-nextjs/package.json" ]; then
            cd website-nextjs

            # Check if reCAPTCHA key is set
            if [ "$FORK_PR" != "true" ]; then
              if [ -z "$NEXT_PUBLIC_RECAPTCHA_SITE_KEY" ]; then
                echo "Error: NEXT_PUBLIC_RECAPTCHA_SITE_KEY is not set"
                exit 1
              else
                echo "âœ“ reCAPTCHA key is configured"
              fi
            else
              echo "Skipping reCAPTCHA key check for PRs from forks."
            fi
            npm install
            npm run build
            cd ..
          else
            echo "Next.js project not found at website-nextjs/package.json. Skipping build check."
          fi

      - name: Setup Conda for benchmark runner
        uses: conda-incubator/setup-miniconda@v3
        with:
          auto-update-conda: true
          python-version: ${{ env.PY_VERSION }}
          # TODO cache conda pkgs dir

      - name: Run sample benchmarks
        shell: bash -el {0}
        run: |
          ./runner/benchmark_all.sh -y "tests" tests/sample_benchmarks_metadata.yaml
          echo ""
          cat results/benchmark_results.csv
          if awk -F',' 'NR>1 {if ($6 != "ok") exit 1}' results/benchmark_results.csv; then
            echo "All benchmarks ran successfully."
          else
            echo "Some benchmarks did not complete successfully."
            exit 1
          fi
